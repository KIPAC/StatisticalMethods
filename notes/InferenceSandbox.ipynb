{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Sandbox\n",
    "\n",
    "### In this notebook, we'll mock up some data from the linear model, as reviewed [here](./LMreview4.ipynb). Then it's your job to implement a Metropolis sampler and constrain the posterior distriubtion. The goal is to play with various strategies for accelerating the convergence and acceptance rate of the chain. Remember to check the convergence and stationarity of your chains, and compare them to the known analytic posterior for this problem!\n",
    "\n",
    "#### Generate a data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0) \n",
    "\n",
    "# the model parameters\n",
    "a = np.pi\n",
    "b = 1.6818\n",
    "\n",
    "# my arbitrary constants\n",
    "mu_x = np.exp(1.0) # see definitions above\n",
    "tau_x = 1.0\n",
    "s = 1.0\n",
    "N = 50 # number of data points\n",
    "\n",
    "# get some x's and y's\n",
    "x = mu_x + tau_x*np.random.randn(N)\n",
    "y = a + b*x + s*np.random.randn(N)\n",
    "\n",
    "plt.plot(x, y, 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package up a log-posterior function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lnPost(params, x, y):\n",
    "    # This is written for clarity rather than numerical efficiency. Feel free to tweak it.\n",
    "    a = params[0]\n",
    "    b = params[1]\n",
    "    lnp = 0.0\n",
    "    # Using informative priors to achieve faster convergence is cheating in this exercise!\n",
    "    # But this is where you would add them.\n",
    "    lnp += -0.5*np.sum((a+b*x - y)**2)\n",
    "    return lnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convenience functions encoding the exact posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExactPosterior:\n",
    "    def __init__(self, x, y, a0, b0):\n",
    "        X = np.matrix(np.vstack([np.ones(len(x)), x]).T)\n",
    "        Y = np.matrix(y).T\n",
    "        self.invcov = X.T * X\n",
    "        self.covariance = np.linalg.inv(self.invcov)\n",
    "        self.mean = self.covariance * X.T * Y\n",
    "        self.a_array = np.arange(0.0, 6.0, 0.02)\n",
    "        self.b_array = np.arange(0.0, 3.25, 0.02)\n",
    "        self.P_of_a = np.array([self.marg_a(a) for a in self.a_array])\n",
    "        self.P_of_b = np.array([self.marg_b(b) for b in self.b_array])\n",
    "        self.P_of_ab = np.array([[self.lnpost(a,b) for a in self.a_array] for b in self.b_array])\n",
    "        self.P_of_ab = np.exp(self.P_of_ab)\n",
    "        self.renorm = 1.0/np.sum(self.P_of_ab)\n",
    "        self.P_of_ab = self.P_of_ab * self.renorm\n",
    "        self.levels = scipy.stats.chi2.cdf(np.arange(1,4)**2, 1) # confidence levels corresponding to contours below\n",
    "        self.contourLevels = self.renorm*np.exp(self.lnpost(a0,b0)-0.5*scipy.stats.chi2.ppf(self.levels, 2))\n",
    "    def lnpost(self, a, b): # the 2D posterior\n",
    "        z = self.mean - np.matrix([[a],[b]])\n",
    "        return -0.5 * (z.T * self.invcov * z)[0,0]\n",
    "    def marg_a(self, a): # marginal posterior of a\n",
    "        return scipy.stats.norm.pdf(a, self.mean[0,0], np.sqrt(self.covariance[0,0]))\n",
    "    def marg_b(self, b): # marginal posterior of b\n",
    "        return scipy.stats.norm.pdf(b, self.mean[1,0], np.sqrt(self.covariance[1,1]))\n",
    "exact = ExactPosterior(x, y, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo some plots of the exact posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(exact.a_array, exact.P_of_a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(exact.b_array, exact.P_of_b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.contour(exact.a_array, exact.b_array, exact.P_of_ab, colors='blue', levels=exact.contourLevels);\n",
    "plt.plot(a, b, 'o', color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, you're almost ready to go! A decidely minimal stub of a Metropolis loop appears below; of course, you don't need to stick exactly with this layout. Once again, after running a chain, be sure to\n",
    "1. visually inspect traces of each parameter to see whether they appear converged  \n",
    "2. compare the marginal and joint posterior distributions to the exact solution to check whether they've converged to the correct distribution\n",
    "> Normally, you should always use quantitative tests of convergence *in addition to* visual inspection, as you saw on Tuesday. For this class (only), let's save some time by relying only on visual impressions and comparison to the exact posterior.\n",
    "\n",
    "(see the snippets farther down)\n",
    "\n",
    "### If you think you have a sampler that works well, use it to run some more chains from different starting points and compare them both visually and using the numerical convergence criteria covered in class.\n",
    "\n",
    "### Once you have a working sampler, the question is: how can we make it converge faster? Experiment! We'll compare notes in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nsamples = # fill in a number\n",
    "samples = np.zeros((Nsamples, 2))\n",
    "# put any more global definitions here\n",
    "\n",
    "for i in range(Nsamples):\n",
    "    a_try, b_try = proposal() # propose new parameter value(s)\n",
    "    lnp_try = lnPost([a_try,b_try], x, y) # calculate posterior density for the proposal\n",
    "    if we_accept_this_proposal(lnp_try, lnp_current):\n",
    "        # do something\n",
    "    else:\n",
    "        # do something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12.0, 3.0)\n",
    "plt.plot(samples[:,0]);\n",
    "plt.plot(samples[:,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "plt.plot(samples[:,0], samples[:,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "plt.hist(samples[:,0], 20, normed=True, color='cyan');\n",
    "plt.plot(exact.a_array, exact.P_of_a, color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "plt.hist(samples[:,1], 20, normed=True, color='cyan');\n",
    "plt.plot(exact.b_array, exact.P_of_b, color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you know how to easily overlay the 2D sample and theoretical confidence regions, by all means do so."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
