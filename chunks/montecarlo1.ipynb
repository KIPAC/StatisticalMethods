{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic Monte Carlo Sampling\n",
    "\n",
    "Goals:\n",
    "* Review the motivation for doing MC sampling in inference, and the basic approaches used.\n",
    "* Get some hands-on experience with the workhorse Metropolis algorithm, and its strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exec(open('../code/montecarlo1.py').read()) # see code here for later demos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* Gelman 1.9, 11.1, 11.2, 11.4, 11.6\n",
    "* MacKay 29.1-29.4, 29.6\n",
    "* Fishman 3.3, 3.6, 6.1-6.4\n",
    "* Ivezic 5.8\n",
    "* Ross 10.2\n",
    "* [Kravtsov notebook on convergence](http://nbviewer.ipython.org/url/astro.uchicago.edu/%7Eandrey/classes/150404_mayacamas/mcmc_convergence.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation: why sample?\n",
    "So far, we've restricted ourselves to inferences with\n",
    "* exact solutions - rare!\n",
    "* low-dimensional parameter spaces - limiting!\n",
    "\n",
    "In general, evaluating the posterior throughout the entire parameter space is too costly. We want to focus resources on mapping the posterior where it is non-tiny. Generating samples from the posterior itself automatically accomplishes this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampling and numerical integration\n",
    "\n",
    "Almost always, we are ultimately interested in *integrals* of the posterior, i.e. marginal distributions of parameters. The tasks of Monte Carlo sampling and **Monte Carlo integration** are essentially indistinguishable. (Similar machinery is useful for difficult optimization problems.)\n",
    "\n",
    "The essence of MC integration:\n",
    "\n",
    "$\\int w(x)\\,p(x)\\,dx = \\int w(x)\\,dP(x) \\approx \\overline{w(x_i)}; ~ x_i\\sim P$\n",
    "\n",
    "i.e., if we can factor the integrand into a PDF and a weight, and sample from the PDF, then our integral becomes an average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Monte Carlo\n",
    "\n",
    "A posterior is already naturally factored into a likelihood function and a prior PDF.\n",
    "\n",
    "$P(\\theta|x) \\propto P(x|\\theta)\\,P(\\theta)$\n",
    "\n",
    "Applying this in the MC integration context leads to the Simple Monte Carlo algorithm:\n",
    "\n",
    "```\n",
    "while we want more samples\n",
    "    draw theta from P(theta)\n",
    "    compute weight = P(x|theta)\n",
    "    store theta and weight\n",
    "```\n",
    "\n",
    "Obtaining marginal distribution(s) for $\\theta$ then reduces to constructing weighted histograms of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simple Monte Carlo\n",
    "\n",
    "SMC is indeed simple (as long as the prior is simple to draw from), but if the priors are not very informative then it still wastes many likelihood evaluations where the posterior is small. However, refinements of this approach lead to some of the advanced algorithms we'll cover later.\n",
    "\n",
    "For now, we'll focus on the most common methods, which use a weight function of unity (i.e. obtain draws directly from the posterior.)\n",
    "\n",
    "But first, a bit more context re: random number generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random number generation\n",
    "Useful terms to know:\n",
    "\n",
    "* Random: predictable only in the sense of following a PDF\n",
    "\n",
    "* Pseudorandom: not random, but \"unpredictable enough\" for practical purposes. Various computer algorithms produce pseudorandom sequences that approximate the uniform distribution on [0,1).\n",
    "\n",
    "* Quasirandom: sequence that doesn't even pretend to be random, but does converge to a target PDF *more quickly* than a random or pseudorandom process would"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random number generation\n",
    "\n",
    "Here we assume that we have a reliable source of uniform pseudorandom numbers, and want to turn these into samples of another PDF.\n",
    "\n",
    "Two simple approaches are\n",
    "1. Inverse transformation\n",
    "2. Rejection sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inverse transform\n",
    "\n",
    "Recall the definition of the CDF (and it's inverse, $F^{-1}$, the quantile function),\n",
    "\n",
    "$F(x) = P(X \\leq x) = \\int_{-\\infty}^x p(x')\\,dx'$\n",
    "\n",
    "By this definition, quantiles of $X$ are uniformly distributed on [0,1]. If $F^{-1}$ is easy to evaluate, we can use this straightforwardly:\n",
    "\n",
    "```\n",
    "draw u from Uniform(0,1)\n",
    "compute x = F_inverse(u)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inverse transform\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_invtrans0.png\" width=100%></td>\n",
    "        <td></td>\n",
    "        <td><img src=\"../graphics/mc1_invtrans1.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: exponential distribution\n",
    "\n",
    "This distribution has $p(x)=\\lambda e^{-\\lambda x}$ and $F(x)=1-e^{-\\lambda x}$ for $x\\geq0$.\n",
    "\n",
    "The quantile function is, therefore, $F^{-1}(P) = -\\ln(1-P)/\\lambda$.\n",
    "\n",
    "Check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lam = 1.0\n",
    "u = np.random.rand(1000)\n",
    "x = -np.log(1-u)/lam\n",
    "plt.rcParams['figure.figsize'] = (15.0,8.0)\n",
    "# plots a histogram of these x's and the exponential PDF\n",
    "inv_trans_demo(x, lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rejection sampling\n",
    "For this method, we need to define an *envelope function* which everywhere exceeds the target PDF, $p(x)$, and can be sampled. Let this be $A\\,g(x)$ where $A$ is a scaling factor and $g(x)$ is a PDF we know.\n",
    "\n",
    "Then the algorithm is\n",
    "```\n",
    "while we want more samples\n",
    "    draw x from g(x)\n",
    "    draw u from Uniform(0,1)\n",
    "    if u <= p(x)/(A*g(x)), keep the sample x\n",
    "    otherwise, reject x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rejection sampling\n",
    "Visually, this corresponds to drawing points that uniformly fill in the space under $p(x)$.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_rejection.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Markov Chain Monte Carlo\n",
    "\n",
    "In general, there's a trade-off between efficiency and generality in sampling algorithms. We've seen already seen examples of the very specialized and efficient (independent sampling) and the very general but inefficient (SMC).\n",
    "\n",
    "We'll cover a number of different algorithms later, but for now let's focus on one that is widely used and simple to implement: the **Metropolis-Hastings** algorithm, which is one example of Markov Chain Monte Carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MCMC\n",
    "A Markov Chain is a sequence where the $n$th entry depends explicitly on the $(n-1)$th, but not (explicitly) on previous steps.\n",
    "\n",
    "For us, the chain will be a random walk through parameter space.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_randomwalk.png\" width=90%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formalities of MCMC\n",
    "\n",
    "Markov chains provide a powerful way to sample PDFs, provided that the transition kernel satisfies a few requirements\n",
    "* Detailed balance: any transition must be reversible; the probability of being at $x$ and moving to $y$ must equal the probability of being at $y$ and moving to $x$\n",
    "* Ergodicity: the process may not be periodic, but it nevertheless must be possible to return to a given state in finite time\n",
    "* It must be possible, in principle, to reach any state with non-zero prior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practicalities of MCMC\n",
    " Chains take time to *converge* to the target distribution\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_burnin.png\" width=100%></td>\n",
    "        <td></td>\n",
    "        <td><img src=\"../graphics/mc1_postburnin.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "1st and 2nd 100 iterations of a chain (blue$\\rightarrow$red with step number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practicalities of MCMC\n",
    "Samples are *correlated*\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_burnin.png\" width=100%></td>\n",
    "        <td></td>\n",
    "        <td><img src=\"../graphics/mc1_postburnin.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "1st and 2nd 100 iterations of a chain (blue$\\rightarrow$red with step number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practicalities of MCMC\n",
    "\n",
    "* Chains take time to *converge* to the target distribution, depending on where they start\n",
    " * We need to verify convergence and throw away this \"burn-in\" period\n",
    "\n",
    "* Samples are *correlated*\n",
    " * We can keep only every $N$th sample without losing much information\n",
    " \n",
    " We'll spend more time looking at these features later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metropolis-Hastings\n",
    "This algorithm can be thought of as an MCMC adaptation of rejection sampling. We need to define\n",
    "1. An initial state (parameter values)\n",
    "2. A proposal distribution, $Q(y|x)$, giving the probability that we attempt to move to $y$ from $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metropolis-Hastings\n",
    "Let $P$ be the distribution we want to sample. The algorithm is then\n",
    "```\n",
    "set x to an initial state\n",
    "compute P(x)\n",
    "while we want more samples\n",
    "    draw y from Q(y|x)\n",
    "    compute P(y)\n",
    "    draw u from Uniform(0,1)\n",
    "    if u <= P(y)/P(x) * Q(x|y)/Q(y|x), set x=y\n",
    "    otherwise, x stays the same\n",
    "    store x as a sample\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metropolis-Hastings\n",
    "Notice that the probability of accepting a  step  (once it's proposed) is\n",
    "\n",
    "$\\alpha(y,x) = \\mathrm{min}\\left[1, \\frac{P(y)Q(x|y)}{P(x)Q(y|x)}\\right]$\n",
    "\n",
    "Let's look again at the requirement of detailed balance\n",
    "\n",
    "> the probability of being at $x$ and moving to $y$ must equal the probability of being at $y$ and moving to $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first of these is $P(x)Q(y|x)\\alpha(y,x)$, where\n",
    "\n",
    "* $P(x)$ is the posterior density (probability of *being* at $x$, if we've sampling $P$ properly)\n",
    "\n",
    "* $Q(y|x)$ is the proposal distribution (probability of attempting a move to $y$ from $x$)\n",
    "\n",
    "* $\\alpha(y,x)$ is the probability of accepting the proposed move\n",
    "\n",
    "With this definition of $\\alpha$, detailed balance is automatically satisfied!\n",
    "\n",
    "$P(x)Q(y|x)\\alpha(y,x) \\equiv P(y)Q(x|y)\\alpha(x,y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metropolis-Hastings\n",
    "Note that **even if a step is rejected, we still keep a sample** (the original state, without moving). The difficulty of finding a temptingly better point is important information!\n",
    "\n",
    "It has been claimed that an *acceptance fraction* of $\\sim25\\%$ is optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metropolis\n",
    "If the proposal distribution is translation invariant, $Q(y|x)=Q\\left(\\left|y-x\\right|\\right)$, then it drops out of the *acceptance ratio* that decides whether to accept a step.\n",
    "\n",
    "$\\alpha(y,x) = \\mathrm{min}\\left[1, \\frac{P(y)}{P(x)}\\right]$\n",
    "\n",
    "This is the original Metropolis algorithm, and is the easiest case to implement.\n",
    "\n",
    "In this case, we *always* accept a jump to higher $P$, and *sometimes* accept one to lower $P$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metropolis implementation\n",
    "This is so important to understand that we'll go through an example and exercise in detail in [this sandbox notebook](../code/mc1_sandbox.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metropolis implementation: discussion points\n",
    "\n",
    "1. How do your results depend on (a) your initial parameter values, (b) the proposal width, (c) the chain length?\n",
    "2. How would you approach a problem (in terms of the choices above) where you already have a good idea of the best fit location?\n",
    "3. How would you approach a problem where you don't have a good idea of where the posterior is likely to be peaked, or whether it has multiple peaks?\n",
    "4. Can you think of ways to improve the acceptance rate in cases (2) and (3) without invalidating the MCMC by violating detailed balance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCMC take-aways\n",
    "We need to be careful about\n",
    "* correlation - we care about not the total number of samples, but the number of independent samples\n",
    "* convergence - we need to verify that chains have converged to the posterior distribution\n",
    "\n",
    "To illustrate, we have 4 chains from the sandbox with different starting points and `width=0.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence tests\n",
    "* Inspection! There is no substitute.\n",
    "* Gelman-Rubin statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence tests - inspection\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_sandbox_ab.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence tests - inspection\n",
    "* How stationary does each sequence appear? \n",
    "* Are all chains sampling the same PDF?\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_sandbox_a.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence tests - inspection\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_sandbox_b.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Conservatively, we might remove the first $\\sim2000$ steps based on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence tests - Gelman-Rubin statistic\n",
    "\n",
    "This approach tests the similarlity of independent chains intended to sample the same PDF. To be meaningful, they should start from different locations and burn-in should be removed.\n",
    "\n",
    "For a given parameter, $\\theta$, the $R$ statistic compares the variance across chains with the variance within a chain. Intuitively, if the chains are random-walking in very different places, i.e. not sampling the same distribution, $R$ will be large.\n",
    "\n",
    "We'd like to see $R\\approx 1$ (e.g. $R<1.1$ is often used)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence tests - Gelman-Rubin statistic\n",
    "In detail, given chains $J=1,\\ldots,m$, each of length $n$,\n",
    "\n",
    "* Let $B=\\frac{n}{m-1} \\sum_j \\left(\\bar{\\theta}_j - \\bar{\\theta}\\right)^2$, where $\\bar{\\theta_j}$ is the average $\\theta$ for chain $j$ and $\\bar{\\theta}$ is the global average. This is proportional to the variance of the individual-chain averages for $\\theta$.\n",
    "\n",
    "* Let $W=\\frac{1}{m}\\sum_j s_j^2$, where $s_j^2$ is the estimated variance of $\\theta$ within chain $j$. This is the average of the individual-chain variances for $\\theta$.\n",
    "\n",
    "* Let $V=\\frac{n-1}{n}W + \\frac{1}{n}B$. This is an estimate for the overall variance of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence tests - Gelman-Rubin statistic\n",
    "\n",
    "Finally, $R=\\sqrt{\\frac{V}{W}}$.\n",
    "\n",
    "Note that this calculation can also be used to track convergence of combinations of parameters, or anything else derived from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation tests\n",
    "* Inspection! Again, no substitute.\n",
    "* Autocorrelation of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation tests - inspection\n",
    "Do subsequent samples look particularly independent?\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_sandbox_a.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation tests - inspection\n",
    "The *autocorrelation* of a sequence, as a function of lag, $k$, is defined thusly:\n",
    "\n",
    "$\\rho_k = \\frac{\\sum_{i=1}^{n-k}\\left(\\theta_{i} - \\bar{\\theta}\\right)\\left(\\theta_{i+k} - \\bar{\\theta}\\right)}{\\sum_{i=1}^{n-k}\\left(\\theta_{i} - \\bar{\\theta}\\right)^2} = \\frac{\\mathrm{Cov}_i\\left(\\theta_i,\\theta_{i+k}\\right)}{\\mathrm{Var}(\\theta)}$\n",
    "\n",
    "The larger lag one needs to get a small autocorrelation, the less informative individual samples are.\n",
    "\n",
    "The `pandas` function `autocorrelation_plot()` may be useful for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation tests\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_sandbox_acf-a.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation tests\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/mc1_sandbox_acf-b.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "We would be justified in thinning the chains by a factor of $\\sim200$, apparently!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Take-aways\n",
    "\n",
    "* Monte Carlo sampling provides a way to characterize posterior distributions without exhaustively exploring the parameter space.\n",
    "\n",
    "* Markov Chain Monte Carlo methods are general enough to accomodate the full power of our Bayesian approach to inference, and are reasonably straightforward to implement.\n",
    "\n",
    "* Later on, we'll look at ways to make MCMC sampling more efficient without sacrificing this generality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical exercise: SMC\n",
    "\n",
    "Implement the Simple Monte Carlo algorithm and use it to sample a toy PDF - perhaps the posterior from the linear model in the sandbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical exercise: rejection sampling\n",
    "\n",
    "Implement a rejection sampler corresponding to the example figure above that illustrates the method. For this example,\n",
    "\n",
    "* $p(x)$ is the $\\chi^2$ distribution with 3 degrees of freedom\n",
    "\n",
    "* $A=\\pi$\n",
    "\n",
    "* $g(x)$ is a normal distribution with mean 0 and standard deviation 5\n",
    "\n",
    "Use a different envelope function if you wish. Verify that your samples do indeed approximate the target PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus brain exercise: Metropolis\n",
    "\n",
    "Hypothetical: a collaborator of yours is having trouble with the fact that rejected steps lead to repeated samples in the Metropolis algorithm. They maintain that just recording the new parameter values whenever a step is accepted ought to be good enough.\n",
    "\n",
    "Without resorting to \"mathematical proofs\" or \"reliable references\", *and without doing any actual sampling*, can you come up with a toy problem that convincingly shows that your collaborator's approach is wrong? The simpler the better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical making-your-life-easier exercise: convergence\n",
    "\n",
    "Write some code to perform the Gelman-Rubin convergence test. Try it out on\n",
    "\n",
    "1. multiple chains from the sandbox notebook. Fiddle with the sampler to get chains that do/do not display nice convergence after e.g. 5000 steps.\n",
    "\n",
    "2. multiple \"chains\" produced from independent sampling, e.g. from the inverse-transform or rejection examples above or one of the examples in previous chunks.\n",
    "\n",
    "You'll be expected to test convergence from now on, so having a function to do so will be helpful.\n",
    "\n",
    "MegaBonus: modify your code to compute the $R$ statistic for the eigenvectors of the covariance of the posterior (yikes). This can be informative when there are strong parameter degeneracies, as in the convergence example above. The eigenvectors can be estimated efficiently from a chain using singular value decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
