{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMINDERS\n",
    "\n",
    "#### Submitting your homework\n",
    "\n",
    "Before doing **anything**,\n",
    "\n",
    "1. **Make a copy** of this notebook in your clone of the [**private** course repository](https://github.com/abmantz/phys366_2019). Edit that copy, not the version in the public repository clone. Please *follow the instructions in the [private repo README](https://github.com/abmantz/phys366_2019/blob/master/README.md)* by locating your solutions on a path like `phys366_2019/HW_week<N>/<Your Name(s)>/` and note that *case matters*. Take a minute to look hard at the directory structure and choose your filenames carefully: **if your solutions are not in the right place they will not be graded**.\n",
    "\n",
    "2. Remember that you will submit your solution by pull request to the **private** repository.\n",
    "\n",
    "#### Submitting your project abstract\n",
    "\n",
    "This week you will submit a **project pitch**. As explained in the [\"Project Milestones\" instructions](https://github.com/KIPAC/StatisticalMethods/blob/master/doc/ProjectMilestones.md#pitch):\n",
    "\n",
    "> Refine your project ideas after recieving feedback on your pitches, and continuing to brainstorm on your own. Update the pitch (which we will now arbitrarily call an abstract) to reflect any changes.\n",
    "\n",
    "This only applies to extant projects, naturally. That is, we only need abstracts for projects that will go forward, which is not necessarily every project that was pitched (if, e.g., some projects have been consolidated after discussions with classmates).\n",
    "\n",
    "Note that, from here on out, these milestones will be organized in the repo by project rather than by person. Therefore, push your (team's) abstract to your fork of the **private repo** in a folder like `phys366_2019/Project_milestones/<project name>/` and submit a PR to the **private** repository. Like the pitch, you can write your abstract in either markdown, plain text, or jupyter notebook form. Do include your names as authors of the abstract, so we know who is working on which project.\n",
    "\n",
    "\n",
    "#### Sending us feedback\n",
    "\n",
    "Once you've submitted your solution, don't forget to also fill out the very quick (and required!) **[weekly feedback form](https://docs.google.com/forms/d/e/1FAIpQLSfH0JGjJd67ANAOcUiRT54nmYtQHViKyOQe-20cny3GDytV6Q/viewform?usp=sf_link).**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Homework\n",
    "\n",
    "## Gibbs Sampling for the Cepheid Period-Luminosity Relation\n",
    "\n",
    "This problem continues the week's tutorial! You'll probably want to re-use the code from that notebook. You could laboriously copy code cells from one notebook to the other. Alternatively, you could export the tutorial notebook as Python code and use `exec(open('mytutorial.py').read())` here. In that case, your solution should include both that raw code and the tutorial notebook (with outputs), since that stuff is part of the solution.\n",
    "\n",
    "# REMINDER!!!\n",
    "\n",
    "Before doing **anything**,\n",
    "\n",
    "1. **Make a copy** of this notebook in your clone of the **private** course repository. Edit that copy, not the version in the public repository clone.\n",
    "\n",
    "2. Remember that you will submit your solution by pull request to the **private** repository. Please **make sure to place your solution at the appropriate path**, as given in the repo's README, `phys366_2019/HW_week5/<your names(s)>/`, and note that _capitalization matters_ (so `Week5` is not the same as `week5`).\n",
    "\n",
    "Once you've submitted your solution, don't forget to also fill out the very quick (and required!) [weekly feedback form](https://docs.google.com/forms/d/e/1FAIpQLSfH0JGjJd67ANAOcUiRT54nmYtQHViKyOQe-20cny3GDytV6Q/viewform?usp=sf_link).\n",
    "\n",
    "# Additional reminder!\n",
    "\n",
    "The final project milestone due next week is a preliminary abstract, essentially a slightly more complete and formal version of your pitch. From here on out, the project milestones will be organized in the repo by *project name* rather than *your name*, so place your (or your group's) abstract in `phys366_2019/Project_milestones/<project name>/Abstract.md` (or whatever file format you prefer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproduce the setup from the tutorial somehow (see above). This includes the definitions of REMOVE_THIS_LINE and REPLACE_WITH_YOUR_SOLUTION, unless you want to see some weird behavior.\n",
    "\n",
    "We do provide some code below, which you are welcome to use, but it assumes that variables have the same names as in the tutorial, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    exec(open('Solution/Cepheids.py').read())\n",
    "except IOError:\n",
    "    REPLACE_WITH_YOUR_SOLUTION()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The posterior\n",
    "\n",
    "We're now going to fit the various parameters of the (simplified) Cepheid model. If you've managed to get through the tutorial without explicitly writing down that posterior, do it now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution by Gibbs sampling\n",
    "\n",
    "Yes! You will now implement a Gibbs sampler to draw from the posterior, which is conveniently fully conjugate (with the right form of priors). If you've been following so far, you know that the model now has the following free parameters:\n",
    "\n",
    "* The true values of $a_i$ and $b_i$ for each galaxy\n",
    "* The hyperparameters $\\bar{a}$, $\\bar{b}$, $\\sigma_a$, and $\\sigma_b$\n",
    "\n",
    "First, work out the fully conditional posterior for each parameter\n",
    "* $p(a_i|...) = $\n",
    "* $p(b_i|...) = $\n",
    "* $p(\\bar{a}|...) = $\n",
    "* $p(\\sigma_{a}|...) = $\n",
    "* $p(\\bar{b}|...) = $\n",
    "* $p(\\sigma_{b}|...) = $\n",
    "\n",
    "We haven't said yet what the priors on the hyperparameters are. [Look up](https://en.wikipedia.org/wiki/Conjugate_prior) what form would make the posterior conjugate, and assign a defensible prior. Is the conjugate prior compatible with something \"uninformative\" (e.g. a uniform prior or the Jeffreys prior)?\n",
    "\n",
    "For $a_i$ and $b_i$, you might need to look up the conditional form of the 2D Gaussian distribution and/or some other Gaussian identities in order to simplify. The RHS is a single, standard PDF in every case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write a function to sample each of the parameters. The beautiful thing about conjugate Gibbs sampling is that the filled-in bulleted list of conditional posteriors above translates directly into the code you need to write.\n",
    "\n",
    "Some code is provided below to organize the parameters and plot results. Use it or not, at your discretion. Caveat emptor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's a free little class to provide access to the free parameter values, and useful subsets of them\n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        # Unless you have a better idea, assume the parameter vector is ordered like\n",
    "        # [a_0, a_1, ..., b_0, b_1, ..., abar, sigma_a, bbar, sigma_b]\n",
    "        self.all = np.zeros(2*len(ngcs)+4) # you will specify starting values later\n",
    "        self.ais = self.all[0:len(ngcs)] # should be a view\n",
    "        self.bis = self.all[len(ngcs):(2*len(ngcs))] # should be a view\n",
    "        self.names = np.concatenate([['a_'+str(int(ngc)) for ngc in ngcs], ['b_'+str(int(ngc)) for ngc in ngcs], \n",
    "                ['abar', 'sigmaa', 'bbar', 'sigmab']])\n",
    "    def a(self): return self.ais # return the whole vector\n",
    "    def b(self): return self.bis # ...\n",
    "    def ai(self, i): return self.ais[i] # return just one\n",
    "    def bi(self, i): return self.bis[i] # ...\n",
    "    def abar(self): return self.all[-4] # get the a and b distribution parameters\n",
    "    def sigmaa(self): return self.all[-3] # ...\n",
    "    def bbar(self): return self.all[-2] # ...\n",
    "    def sigmab(self): return self.all[-1] # ...\n",
    "    def set_ai(self, i, v): self.ais[i] = v # set parameters\n",
    "    def set_bi(self, i, v): self.bis[i] = v # ...\n",
    "    def set_abar(self, v): self.all[-4] = v\n",
    "    def set_sigmaa(self, v): self.all[-3] = v\n",
    "    def set_bbar(self, v): self.all[-2] = v\n",
    "    def set_sigmab(self, v): self.all[-1] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a Parameters object. Initially, all parameters are given a value of zero in the code above, which is a problem for the sigmas. The code below avoids dividing by zero, but doesn't do anything about setting an intelligent starting point. Do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Parameters()\n",
    "p.set_sigmaa(1.0)\n",
    "p.set_sigmab(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define whatever variables you need to specifiy your priors, and a function/functions to update all of the values in the an object of class Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    exec(open('Solution/sampler.py').read())\n",
    "except IOError:\n",
    "    REMOVE_THIS_LINE()\n",
    "    def sample(current_params):\n",
    "        REPLACE_WITH_YOUR_SOLUTION()\n",
    "    # probably some other utility functions, and definitions that specify priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array to hold the chain, and run the sampler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nsteps = 10000 # change as you see fit\n",
    "chain = np.zeros((Nsteps,len(p.all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(chain.shape[0]):\n",
    "    sample(p)\n",
    "    chain[i,:] = p.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12.0, 64.0)\n",
    "for j in range(chain.shape[1]):\n",
    "    plt.subplot(chain.shape[1], 1, j+1)\n",
    "    plt.plot(chain[:,j])\n",
    "    plt.ylabel(p.names[j], fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove burn-in; do any thinning you want to do; verify convergence and robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, look at the posterior for the hyperparameters, and offer an answer to the question posed at the top of the notebook: is the P-L relation universal according to these data, or is there evidence for additional scatter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convenient for looking at the 1D and 2D posteriors of a few parameters\n",
    "corner.corner(chain[:,18:22], show_titles=True, labels=p.names[18:22]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus (not had enough yet?)\n",
    "\n",
    "Here are some ideas for digging deeper with this problem:\n",
    "1. Constrain the distributions of $a$ and $b$ using Metropolis sampling (or some other sampler of your choice) and compare performance.\n",
    "2. Extend the model such that the joint distribution of $a$ and $b$ is a 2D Gaussian, with a $2 \\times 2$ covariance matrix describing the scatter.\n",
    "3. Constrain the model *without* using the WLS trick (sampling all of the Cepheid magnitudes) using the sampler of your choice. Who knows, maybe you'll find one that that can handle the challenge gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
