{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Fitting a Simple Microlensing Model to an OGLE Lightcurve\n",
    "\n",
    "Here we'll pick up from the introduction in the [OGLE](ogle_lightcurve.pynb) notebook. Our goal will be to\n",
    "1. see our simpleminded Metropolis implementation struggle with a real-world problem, and then\n",
    "2. apply a more efficient implementation or algorithm (using a package) for comparison.\n",
    "\n",
    "## Data and model\n",
    "\n",
    "Let's read in the data, as in the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('tbc.py').read()) # define TBC and TBC_above\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "%matplotlib inline\n",
    "import incredible as cr\n",
    "from corner import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBC()\n",
    "# dat = np.loadtxt('../ignore/phot.dat') # edit path if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dat[:,0]\n",
    "I = dat[:,1]\n",
    "Ierr = dat[:,2]\n",
    "\n",
    "t0 = 2450000.\n",
    "t -= t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we'll organize the data in a dictionary as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'t':t, 'I':I, 'Ierr':Ierr, 't0':t0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, copy over your model evaluation function from the [`ogle_lightcurve`](ogle_lightcurve.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_I(t, I0, p, tmax, tE):\n",
    "    \"\"\"\n",
    "    Return the model lightcurve in magnitude units, I(t)\n",
    "    \"\"\"\n",
    "    TBC()\n",
    "\n",
    "TBC_above()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, sketch the PGM and write out the probability expressions corresponding to the data set and the model given in the [`ogle_lightcurve`](ogle_lightcurve.ipynb) notebook. (We'll think about the priors below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _TBC_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to chose priors. As always, you can experiment with different choices if you think they're justified. But for concreteness, and to enable comparison with a known solution, consider the following as a default.\n",
    "\n",
    "This seems like a situation where uniform priors are reasonable for all parameters. Note that $p\\geq0$ is a physical requirement of the model definition (and $p>0$ is a numerical requirement, to avoid dividing by zero). Bounds for the prior distributions in $I_0$, $t_\\mathrm{max}$ and $t_\\mathrm{E}$ may not be obvious (strictly) a priori, but could be based on an absolutely minimal use of the data. For example, given that these lightcurves correspond to intervals the OGLE pipeline believes it found a microlensing event, it's reasonable to assume that $t_\\mathrm{max}$ lies somewhere within the lightcurve, and similarly that the width $t_\\mathrm{E}$ be less than the duration of the lightcurve, and that, for e.g., $I_0$ lies between the minimum and maximum of the measured $I(t)$ (maybe with an extra buffer of 1-2 magnitudes, if you want). Write down your chosen priors here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _TBC_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation\n",
    "\n",
    "Implement log-prior, log-likelihood and log-posterior functions. The prototypes are of the same form we've been using, which is hopefully familiar now. For concreteness, and to agree with the argument list of `model_I`, let's call the parameters `I0`, `p`, `tmax` and `tE` in code, and also define a `params` dictionary as usual. The `data` argument will be the dictionary we actually called `data` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBC() # params = {'I0': ... put in broadly reasonable starting parameters from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(**params):\n",
    "    TBC()\n",
    "    \n",
    "TBC_above()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "log_prior(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(data, **params):\n",
    "    TBC()\n",
    "    \n",
    "TBC_above()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "log_likelihood(data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(data, **params):\n",
    "    TBC()\n",
    "    \n",
    "TBC_above()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "log_posterior(data, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either use your guess as a starting point for a chain, or insert some cells here and use a numerical minimizer to get `params` closer to the best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with simple Metropolis\n",
    "\n",
    "We'll first try to use your Metropolis implementation from the [AGN photometry tutorials](agn_photometry_metro.ipynb), and see how well that does.\n",
    "\n",
    "Define a proposal distribution with guesses for step sizes for each parameter, as we did in that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBC()\n",
    "# proposal_distribution = {'I0': ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can copy over your `propose` and `step` functions from that notebook also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose(current_params, dists):\n",
    "    TBC()\n",
    "    \n",
    "def step(data, current_params, current_lnP, proposal_dists):\n",
    "    TBC()\n",
    "    \n",
    "TBC_above()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a single chain to see how things are working. As before, you might want to go back and adjust the proposal distribution based on what you see below. There is nothing magic about the length of 10000 other than it's a nice round number that should be more than enough when we switch to a more advanced sampler. It should also be long enough for even a struggling sampler to move around at least a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "current_lnP = log_posterior(data, **params)\n",
    "\n",
    "samples = np.zeros((10000, len(params)))\n",
    "for i in range(samples.shape[0]):\n",
    "    params, current_lnP = step(data, params, current_lnP, proposal_distribution)\n",
    "    samples[i,:] = [params['I0'], params['p'], params['tmax'], params['tE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the traces as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_labels = [r'$I_0$', r'$p$', r'$t_{max}$', r'$t_E$']\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "fig, ax = plt.subplots(len(param_labels), 1);\n",
    "cr.plot_traces(samples, ax, labels=param_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming this looks broadly reasonable, we can now run a few more, with dispersed starting points. Remember that these chains don't need to look perfect, since we're also going to use a more advanced sampler below.\n",
    "\n",
    "In fact, this is a pretty nasty parameter space, at least for my stupid Metropolis sampler, so dispersing starting points within very wide priors is a bad idea. The cell below disperses parameters by something like 5x the standard deviations of your test chain, which will hopefully be ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chains = [np.zeros((10000, len(params))) for j in range(4)]\n",
    "\n",
    "for newsamples in chains:\n",
    "    params = {'I0':st.norm.rvs(params['I0'], 5*np.std(samples[:,0])),\n",
    "              'p':st.norm.rvs(params['p'], 5*np.std(samples[:,1])),\n",
    "              'tmax':st.norm.rvs(params['tmax'], 5*np.std(samples[:,2])),\n",
    "              'tE':st.norm.rvs(params['tE'], 5*np.std(samples[:,3]))\n",
    "             }\n",
    "    current_lnP = log_posterior(data, **params)\n",
    "    for i in range(samples.shape[0]):\n",
    "        params, current_lnP = step(data, params, current_lnP, proposal_distribution)\n",
    "        newsamples[i,:] = [params['I0'], params['p'], params['tmax'], params['tE']]\n",
    "    print(\"Done with a chain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, our next move is to inspect the trace plots. Remember what we're looking for from the [MCMC Diagnostics notebook](mcmc_diagnostics.ipynb)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "fig, ax = plt.subplots(len(param_labels), 1);\n",
    "cr.plot_traces(chains, ax, labels=param_labels, Line2D_kwargs={'markersize':1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove burn-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBC() # burn = ...\n",
    "chains = [chain[burn:,:] for chain in chains]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the other diagnostics we covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBC() # compute the Gelman-Rubin criterion for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBC() # compute the effective number of samples for each parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Without too much fiddling, I was able to get good convergence, but not a particularly large $n_\\mathrm{eff}$ (hundreds). If your chains are similar, you're in good shape, considering!\n",
    "\n",
    "In fact, let's also quickly look at the posterior mean of each parameter as a cross check that your solution is broadly sound. Mine are about [19.822, 0.2662, 7434.4, 194.5]. Of course, this is only useful to know if you used the same data and priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.concatenate(chains, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, let's make a quick triangle plot. If you have as few effectively independent samples as I do, it will be ugly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner(np.concatenate(chains, axis=0), labels=param_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit with a better sampler\n",
    "\n",
    "Now the fun, and more open-ended part! Fit the same data and model, but using a different sampler. This sampler can be provided by some Python package that you can `pip` or `conda` install. In fact, we encourage this, as it forces you to learn to use software that might be useful in general.\n",
    "\n",
    "You can use a more efficient Metropolis-Hastings sampler (e.g. with adaptation) or some other sampling method entirely. However, we would discourage treating these things as black boxes, so stick to methods where you have a reasonable idea what's happening under the hood. We refer you to the notes on [More Sampling Methods](../notes/more_samplers.ipynb) and our incomplete list of [sampling packages](../notes/MC_packages.ipynb), though in principle you need not restrict yourself to these.\n",
    "\n",
    "Once you've installed and figured out how to use one of these things, run several chains as we did above and look at the usual diagnostics. (This assumes that the concept of \"multiple chains\" makes sense for the method you're using. If not, show and discuss whatever diagnostics make sense for that method.)\n",
    "\n",
    "Verify that you get essentially the same results as above (modulo the poorer sampling of simple our Metropolis implementation - a visual check is fine for this), and comment on the relative efficiency of the two algorithms.\n",
    "\n",
    "For compatibility with the remainder of the notebook, store your final list of samples in a single $N\\times4$ array called `samples`. For multiple chains arranged as we're used to, like in the previous section, this could be done by `samples = np.concatenate(chains, axis=0)` (after removing burn-in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBC() # all the stuff above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _TBC comments on the efficiency, results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the fitted model to the data\n",
    "\n",
    "As a simple check of whether the fit is reasonable, the cell below will plot the model curve defined by the posterior mean over the data. We can't possibly claim to be finished without looking at this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_params = np.mean(samples, axis=0)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7.0, 5.0)\n",
    "plt.errorbar(t, I, yerr=Ierr, fmt='none');\n",
    "plt.xlabel('HJD - '+str(t0), fontsize=14);\n",
    "plt.ylabel('I-band magnitude', fontsize=14);\n",
    "plt.gca().invert_yaxis();\n",
    "tgrid = np.linspace(t.min(), t.max(), 1000)\n",
    "plt.plot(tgrid, model_I(tgrid, *mean_params));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results\n",
    "\n",
    "Similarly, we're not done without finding the 1D marginalized best values and 68.3% credible intervals for each parameter. Do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $I_0 =$ this $\\pm$ that, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** For the reference data set and priors, I find $I_0=19.8230\\pm0.0017$, $p=0.2663\\pm0.0013$, $t_\\mathrm{max}=7434.4\\pm0.4$ and $t_\\mathrm{E}=194.6\\pm1.0$."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
